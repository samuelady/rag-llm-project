{"text": "Germany Charles Le Grand, USA Torsten Duwe, SUSE, Germany Dave Lauer, USA Alexander J. Herzog, USA John Hoffoss, Minnesota State Colleges and Universities, USA Drexx Laggui, L&A Inc, Philippines Mike Mooney, USA Ruud van der Meulen, Netherlands Pablo Endres, Venezuela / Germany Chris Gatford, HackLabs, Australia Jeremy Wilde, compliancetutorial.com, UK / France Wim Remes, Belgium Rob J. Meijer, Netherlands Gary Axten, UK / Spain Mike Simpson, USA / Germany Alan Tang, UK Jason Woloz, USA John R. Moser, USA Tom O’Connor, Ireland Mike Vasquez, City of Mesa, USA Creative Commons 3.0 Attribution-Non-Commercial-NoDerivs 2010, ISECOM, www.isecom.org, www.osstmm.org 6\\nForeword Security verification used to require a cross-disciplinary specialist who understood security as deeply as they understood the rules, laws, underlying premise, operation, process, and technology involved. Sometime later, third party verification came from the popular notion of builder blindness that says those closest to the target will generally and usually involuntarily miss the most problems. This became the standard procedure for a while and is still widely regarded as true even though it actually means that an outsider with less knowledge of the target is supposedly more capable of understanding that target than the operator. At some point, the pendulum began to swing back the other way. Whether this happened for either efficiency or economic reasons is unclear, but it has brought about an important shift to provide the operators with security testing ability. It has led to simplified frameworks, software, checklists, tool kits, and many other ways to make security testing easy enough that anyone can do it. That’s a good thing. Unfortunately, there is no complex subject for which the simplification process is not itself complex nor the end result significantly less than the whole. This means that to make a security testing solution simple enough for non-experts to execute, the solution requires a complex back-end to collect the data according to preconceived rules. This assumes that operations always run according to design and configuration. It also assumes the solution developer has taken into account all the possibilities for where, what, and how data can be gathered. Furthermore it assumes that the data gathered can be properly sorted into a uniform format for comparison and rule-based analysis. None of those tasks are simple. Assuming that can be done, it would still require an exhaustive database of possibilities for the numerous representations of security and layers of controls to deduce security problems. While minimizing false positives through correlations based on the rules, laws, underlying premise, operation, process, and technology involved. This solution could then be able to provide a clear, concise report and metric. This solution would need to have more than just the framework, software, checklist, or toolkit which it produces; it would need a methodology. A security methodology is not a simple thing. It is the back-end of a process or solution which defines what or who is tested as well as when and where. It must take a complex process and reduce it into elemental processes and sufficiently explain", "metadata": {"doc_id": "OSSTMM.3", "chunk_id": 4}}